
You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/tmp/ipykernel_80978/1142868687.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  load_accuracy = load_metric("accuracy")
{'eval_loss': 0.851780354976654, 'eval_accuracy': 0.673785594639866, 'eval_f1': 0.2683679426236344, 'eval_runtime': 107.2917, 'eval_samples_per_second': 22.257, 'eval_steps_per_second': 1.398, 'epoch': 0.02}
{'eval_loss': 0.7875227928161621, 'eval_accuracy': 0.673785594639866, 'eval_f1': 0.2683679426236344, 'eval_runtime': 106.4896, 'eval_samples_per_second': 22.425, 'eval_steps_per_second': 1.409, 'epoch': 0.03}
{'eval_loss': 0.7443206906318665, 'eval_accuracy': 0.673785594639866, 'eval_f1': 0.2683679426236344, 'eval_runtime': 105.273, 'eval_samples_per_second': 22.684, 'eval_steps_per_second': 1.425, 'epoch': 0.05}
{'eval_loss': 0.7358457446098328, 'eval_accuracy': 0.6746231155778895, 'eval_f1': 0.27063221998744436, 'eval_runtime': 107.4311, 'eval_samples_per_second': 22.228, 'eval_steps_per_second': 1.396, 'epoch': 0.07}
{'eval_loss': 0.7232962250709534, 'eval_accuracy': 0.6742043551088778, 'eval_f1': 0.2695017684351017, 'eval_runtime': 108.1043, 'eval_samples_per_second': 22.09, 'eval_steps_per_second': 1.388, 'epoch': 0.08}
{'eval_loss': 0.6831508278846741, 'eval_accuracy': 0.714824120603015, 'eval_f1': 0.36570935466436366, 'eval_runtime': 109.8455, 'eval_samples_per_second': 21.74, 'eval_steps_per_second': 1.366, 'epoch': 0.1}
{'eval_loss': 0.6272279620170593, 'eval_accuracy': 0.7734505862646566, 'eval_f1': 0.480689454813042, 'eval_runtime': 121.0906, 'eval_samples_per_second': 19.721, 'eval_steps_per_second': 1.239, 'epoch': 0.12}
{'eval_loss': 0.599385678768158, 'eval_accuracy': 0.791038525963149, 'eval_f1': 0.4959805769054324, 'eval_runtime': 120.2641, 'eval_samples_per_second': 19.856, 'eval_steps_per_second': 1.247, 'epoch': 0.13}
{'eval_loss': 0.5908350944519043, 'eval_accuracy': 0.7897822445561139, 'eval_f1': 0.5113244137882943, 'eval_runtime': 121.8564, 'eval_samples_per_second': 19.597, 'eval_steps_per_second': 1.231, 'epoch': 0.15}
{'eval_loss': 0.5985152125358582, 'eval_accuracy': 0.7981574539363484, 'eval_f1': 0.5030792417375219, 'eval_runtime': 122.8276, 'eval_samples_per_second': 19.442, 'eval_steps_per_second': 1.221, 'epoch': 0.17}
{'eval_loss': 0.5920106768608093, 'eval_accuracy': 0.7964824120603015, 'eval_f1': 0.5005632218852769, 'eval_runtime': 128.3963, 'eval_samples_per_second': 18.599, 'eval_steps_per_second': 1.168, 'epoch': 0.18}
{'eval_loss': 0.5661307573318481, 'eval_accuracy': 0.8052763819095478, 'eval_f1': 0.5185651039928733, 'eval_runtime': 109.7546, 'eval_samples_per_second': 21.758, 'eval_steps_per_second': 1.367, 'epoch': 0.2}
{'eval_loss': 0.5900107622146606, 'eval_accuracy': 0.8015075376884422, 'eval_f1': 0.5091930880762349, 'eval_runtime': 111.7532, 'eval_samples_per_second': 21.369, 'eval_steps_per_second': 1.342, 'epoch': 0.22}
{'eval_loss': 0.5670706629753113, 'eval_accuracy': 0.8023450586264657, 'eval_f1': 0.5188981117387689, 'eval_runtime': 109.4682, 'eval_samples_per_second': 21.815, 'eval_steps_per_second': 1.37, 'epoch': 0.23}
{'eval_loss': 0.6000213623046875, 'eval_accuracy': 0.8044388609715243, 'eval_f1': 0.5113701945452852, 'eval_runtime': 106.6709, 'eval_samples_per_second': 22.387, 'eval_steps_per_second': 1.406, 'epoch': 0.25}
{'eval_loss': 0.5931097865104675, 'eval_accuracy': 0.7784757118927973, 'eval_f1': 0.5122497440679924, 'eval_runtime': 115.5068, 'eval_samples_per_second': 20.674, 'eval_steps_per_second': 1.299, 'epoch': 0.27}
{'eval_loss': 0.5476913452148438, 'eval_accuracy': 0.8065326633165829, 'eval_f1': 0.5220273126015691, 'eval_runtime': 112.0086, 'eval_samples_per_second': 21.32, 'eval_steps_per_second': 1.339, 'epoch': 0.28}
{'eval_loss': 0.5572683811187744, 'eval_accuracy': 0.8107202680067002, 'eval_f1': 0.5205974081503046, 'eval_runtime': 109.738, 'eval_samples_per_second': 21.761, 'eval_steps_per_second': 1.367, 'epoch': 0.3}
{'eval_loss': 0.5586408972740173, 'eval_accuracy': 0.7960636515912898, 'eval_f1': 0.5206076508271945, 'eval_runtime': 107.7744, 'eval_samples_per_second': 22.157, 'eval_steps_per_second': 1.392, 'epoch': 0.32}
{'eval_loss': 0.5498247146606445, 'eval_accuracy': 0.8107202680067002, 'eval_f1': 0.524733715647149, 'eval_runtime': 109.6048, 'eval_samples_per_second': 21.787, 'eval_steps_per_second': 1.369, 'epoch': 0.34}
{'eval_loss': 0.5829324722290039, 'eval_accuracy': 0.8036013400335008, 'eval_f1': 0.5082448756139147, 'eval_runtime': 107.8862, 'eval_samples_per_second': 22.134, 'eval_steps_per_second': 1.39, 'epoch': 0.35}
{'eval_loss': 0.5730807781219482, 'eval_accuracy': 0.7843383584589615, 'eval_f1': 0.5124248687922257, 'eval_runtime': 107.8079, 'eval_samples_per_second': 22.151, 'eval_steps_per_second': 1.391, 'epoch': 0.37}
{'eval_loss': 0.5703715085983276, 'eval_accuracy': 0.7914572864321608, 'eval_f1': 0.5178915543838823, 'eval_runtime': 107.4779, 'eval_samples_per_second': 22.219, 'eval_steps_per_second': 1.396, 'epoch': 0.39}
{'eval_loss': 0.5408852100372314, 'eval_accuracy': 0.8069514237855946, 'eval_f1': 0.5216937493700771, 'eval_runtime': 108.0267, 'eval_samples_per_second': 22.106, 'eval_steps_per_second': 1.389, 'epoch': 0.4}
{'eval_loss': 0.548622190952301, 'eval_accuracy': 0.8119765494137353, 'eval_f1': 0.5236698622924719, 'eval_runtime': 111.5391, 'eval_samples_per_second': 21.41, 'eval_steps_per_second': 1.345, 'epoch': 0.42}
{'eval_loss': 0.563991367816925, 'eval_accuracy': 0.8082077051926299, 'eval_f1': 0.5179317931793178, 'eval_runtime': 115.8866, 'eval_samples_per_second': 20.606, 'eval_steps_per_second': 1.294, 'epoch': 0.44}
{'eval_loss': 0.5524933934211731, 'eval_accuracy': 0.8086264656616415, 'eval_f1': 0.5182415149682703, 'eval_runtime': 107.596, 'eval_samples_per_second': 22.194, 'eval_steps_per_second': 1.394, 'epoch': 0.45}
{'eval_loss': 0.5425622463226318, 'eval_accuracy': 0.8086264656616415, 'eval_f1': 0.5260065929773804, 'eval_runtime': 105.5936, 'eval_samples_per_second': 22.615, 'eval_steps_per_second': 1.421, 'epoch': 0.47}
{'eval_loss': 0.5598961710929871, 'eval_accuracy': 0.8040201005025126, 'eval_f1': 0.5089839300613052, 'eval_runtime': 107.4674, 'eval_samples_per_second': 22.221, 'eval_steps_per_second': 1.396, 'epoch': 0.49}
{'eval_loss': 0.550446093082428, 'eval_accuracy': 0.8123953098827471, 'eval_f1': 0.524423502276385, 'eval_runtime': 113.9688, 'eval_samples_per_second': 20.953, 'eval_steps_per_second': 1.316, 'epoch': 0.5}
{'eval_loss': 0.55610591173172, 'eval_accuracy': 0.8073701842546064, 'eval_f1': 0.5149476582246758, 'eval_runtime': 110.5153, 'eval_samples_per_second': 21.608, 'eval_steps_per_second': 1.357, 'epoch': 0.52}
{'eval_loss': 0.5510984659194946, 'eval_accuracy': 0.8061139028475712, 'eval_f1': 0.51976359979092, 'eval_runtime': 108.8429, 'eval_samples_per_second': 21.94, 'eval_steps_per_second': 1.378, 'epoch': 0.54}
{'eval_loss': 0.5574213266372681, 'eval_accuracy': 0.8082077051926299, 'eval_f1': 0.5194142959569089, 'eval_runtime': 109.28, 'eval_samples_per_second': 21.852, 'eval_steps_per_second': 1.373, 'epoch': 0.55}
{'eval_loss': 0.5467953085899353, 'eval_accuracy': 0.8098827470686767, 'eval_f1': 0.5228424281966212, 'eval_runtime': 107.541, 'eval_samples_per_second': 22.205, 'eval_steps_per_second': 1.395, 'epoch': 0.57}
{'eval_loss': 0.5518028140068054, 'eval_accuracy': 0.7989949748743719, 'eval_f1': 0.5261512541058381, 'eval_runtime': 107.6858, 'eval_samples_per_second': 22.176, 'eval_steps_per_second': 1.393, 'epoch': 0.59}
{'eval_loss': 0.5482466220855713, 'eval_accuracy': 0.8098827470686767, 'eval_f1': 0.5300932425664567, 'eval_runtime': 107.4672, 'eval_samples_per_second': 22.221, 'eval_steps_per_second': 1.396, 'epoch': 0.6}
{'eval_loss': 0.5408523082733154, 'eval_accuracy': 0.8111390284757118, 'eval_f1': 0.5364014658955666, 'eval_runtime': 106.1802, 'eval_samples_per_second': 22.49, 'eval_steps_per_second': 1.413, 'epoch': 0.62}
{'eval_loss': 0.5495284795761108, 'eval_accuracy': 0.8103015075376885, 'eval_f1': 0.5378163831544954, 'eval_runtime': 109.1185, 'eval_samples_per_second': 21.884, 'eval_steps_per_second': 1.375, 'epoch': 0.64}
{'eval_loss': 0.5507949590682983, 'eval_accuracy': 0.8111390284757118, 'eval_f1': 0.5361682423864794, 'eval_runtime': 107.0351, 'eval_samples_per_second': 22.31, 'eval_steps_per_second': 1.401, 'epoch': 0.65}
{'eval_loss': 0.5617803335189819, 'eval_accuracy': 0.8010887772194305, 'eval_f1': 0.5274644178565157, 'eval_runtime': 107.6154, 'eval_samples_per_second': 22.19, 'eval_steps_per_second': 1.394, 'epoch': 0.67}
{'eval_loss': 0.5489957928657532, 'eval_accuracy': 0.8103015075376885, 'eval_f1': 0.5306450401567713, 'eval_runtime': 109.293, 'eval_samples_per_second': 21.85, 'eval_steps_per_second': 1.372, 'epoch': 0.69}
{'eval_loss': 0.5475658774375916, 'eval_accuracy': 0.8115577889447236, 'eval_f1': 0.5238449698598263, 'eval_runtime': 109.7042, 'eval_samples_per_second': 21.768, 'eval_steps_per_second': 1.367, 'epoch': 0.7}
{'eval_loss': 0.5414228439331055, 'eval_accuracy': 0.8090452261306532, 'eval_f1': 0.5306376461639788, 'eval_runtime': 109.4351, 'eval_samples_per_second': 21.821, 'eval_steps_per_second': 1.371, 'epoch': 0.72}
{'eval_loss': 0.5292543172836304, 'eval_accuracy': 0.8153266331658291, 'eval_f1': 0.5292508713760922, 'eval_runtime': 108.9221, 'eval_samples_per_second': 21.924, 'eval_steps_per_second': 1.377, 'epoch': 0.74}
{'eval_loss': 0.5595188140869141, 'eval_accuracy': 0.8140703517587939, 'eval_f1': 0.5339447962871361, 'eval_runtime': 109.275, 'eval_samples_per_second': 21.853, 'eval_steps_per_second': 1.373, 'epoch': 0.75}
{'eval_loss': 0.5297725200653076, 'eval_accuracy': 0.8132328308207705, 'eval_f1': 0.5383558351566156, 'eval_runtime': 108.0681, 'eval_samples_per_second': 22.097, 'eval_steps_per_second': 1.388, 'epoch': 0.77}
{'eval_loss': 0.5309138298034668, 'eval_accuracy': 0.8132328308207705, 'eval_f1': 0.53591402615138, 'eval_runtime': 108.0403, 'eval_samples_per_second': 22.103, 'eval_steps_per_second': 1.388, 'epoch': 0.79}
{'eval_loss': 0.5328757166862488, 'eval_accuracy': 0.8132328308207705, 'eval_f1': 0.5237714920386496, 'eval_runtime': 107.3711, 'eval_samples_per_second': 22.241, 'eval_steps_per_second': 1.397, 'epoch': 0.8}
{'eval_loss': 0.5304533839225769, 'eval_accuracy': 0.8132328308207705, 'eval_f1': 0.5314362386957668, 'eval_runtime': 109.588, 'eval_samples_per_second': 21.791, 'eval_steps_per_second': 1.369, 'epoch': 0.82}
{'loss': 0.5831, 'learning_rate': 1.4416527079843662e-05, 'epoch': 0.84}
{'eval_loss': 0.5559678077697754, 'eval_accuracy': 0.8015075376884422, 'eval_f1': 0.5510515665890976, 'eval_runtime': 107.4223, 'eval_samples_per_second': 22.23, 'eval_steps_per_second': 1.396, 'epoch': 0.84}
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'eval_loss': 0.5207472443580627, 'eval_accuracy': 0.8161641541038526, 'eval_f1': 0.5393439714258657, 'eval_runtime': 107.9107, 'eval_samples_per_second': 22.129, 'eval_steps_per_second': 1.39, 'epoch': 0.85}
{'eval_loss': 0.5607105493545532, 'eval_accuracy': 0.8069514237855946, 'eval_f1': 0.5480796082734795, 'eval_runtime': 110.3137, 'eval_samples_per_second': 21.647, 'eval_steps_per_second': 1.36, 'epoch': 0.87}
{'eval_loss': 0.5321434736251831, 'eval_accuracy': 0.8119765494137353, 'eval_f1': 0.5316893069945818, 'eval_runtime': 110.5672, 'eval_samples_per_second': 21.598, 'eval_steps_per_second': 1.357, 'epoch': 0.89}
{'train_runtime': 7200.3823, 'train_samples_per_second': 3.978, 'train_steps_per_second': 0.249, 'train_loss': 0.5791006754029472, 'epoch': 0.89}
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
To https://huggingface.co/IAyoub/finetuning-sentiment-model-base-zero-shot
   5c68dd4..b17bf6c  main -> main
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
To https://huggingface.co/IAyoub/finetuning-sentiment-model-base-zero-shot
   b17bf6c..41905ec  main -> main
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers
